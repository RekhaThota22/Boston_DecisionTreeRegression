# Boston_DecisionTreeRegression
"Every dataset tells a story, and every model iteration is a chapter in my continuous upskilling journey in Machine Learning. Thrilled with my latest finding using a Decision Tree Regressor on the Boston Housing data!" 

Initially, I tried predicting 'MEDV' using only 'RM' (average number of rooms per dwelling). The model performed okay, but there was room for improvement.

Then, I added 'LSTAT' (% lower status of the population) to the feature set. The result? A significant drop in model error! ðŸŽ‰
This clearly showed how complementary features supercharge predictive power. 'RM' gives us the property's size, while 'LSTAT' provides crucial neighborhood context. A Decision Tree, in particular, thrives on this kind of rich, interacting information, allowing it to build more precise rules.

It's a powerful reminder that in machine learning, the more relevant and diverse information you feed your model, the smarter its predictions become.
